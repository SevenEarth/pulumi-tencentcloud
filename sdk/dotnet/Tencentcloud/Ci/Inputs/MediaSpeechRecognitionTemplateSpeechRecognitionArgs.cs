// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace TencentCloudIAC.PulumiPackage.Tencentcloud.Ci.Inputs
{

    public sealed class MediaSpeechRecognitionTemplateSpeechRecognitionArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Number of voice channels: 1 means mono. EngineModelType supports only mono for non-telephone scenarios, and 2 means dual channels (only 8k_zh engine model supports dual channels, which should correspond to both sides of the call).
        /// </summary>
        [Input("channelNum", required: true)]
        public Input<string> ChannelNum { get; set; } = null!;

        /// <summary>
        /// Whether to perform intelligent conversion of Arabic numerals (currently supports Mandarin Chinese engine): 0 means no conversion, directly output Chinese numbers, 1 means intelligently convert to Arabic numerals according to the scene, 3 means enable math-related digital conversion, the default value is 0.
        /// </summary>
        [Input("convertNumMode")]
        public Input<string>? ConvertNumMode { get; set; }

        /// <summary>
        /// Engine model type, divided into phone scene and non-phone scene, phone scene: 8k_zh: phone 8k Chinese Mandarin general (can be used for dual-channel audio), 8k_zh_s: phone 8k Chinese Mandarin speaker separation (only for monophonic audio), 8k_en: Telephone 8k English; non-telephone scene: 16k_zh: 16k Mandarin Chinese, 16k_zh_video: 16k audio and video field, 16k_en: 16k English, 16k_ca: 16k Cantonese, 16k_ja: 16k Japanese, 16k_zh_edu: Chinese education, 16k_en_edu: English education, 16k_zh_medical: medical, 16k_th: Thai, 16k_zh_dialect: multi-dialect, supports 23 dialects.
        /// </summary>
        [Input("engineModelType", required: true)]
        public Input<string> EngineModelType { get; set; } = null!;

        /// <summary>
        /// Whether to filter dirty words (currently supports Mandarin Chinese engine): 0 means not to filter dirty words, 1 means to filter dirty words, 2 means to replace dirty words with *, the default value is 0.
        /// </summary>
        [Input("filterDirty")]
        public Input<string>? FilterDirty { get; set; }

        /// <summary>
        /// Whether to pass modal particles (currently supports Mandarin Chinese engine): 0 means not to filter modal particles, 1 means partial filtering, 2 means strict filtering, and the default value is 0.
        /// </summary>
        [Input("filterModal")]
        public Input<string>? FilterModal { get; set; }

        /// <summary>
        /// Whether to filter punctuation (currently supports Mandarin Chinese engine): 0 means no filtering, 1 means filtering end-of-sentence punctuation, 2 means filtering all punctuation, the default value is 0.
        /// </summary>
        [Input("filterPunc")]
        public Input<string>? FilterPunc { get; set; }

        /// <summary>
        /// Output file type, optional txt, srt. The default is txt.
        /// </summary>
        [Input("outputFileType")]
        public Input<string>? OutputFileType { get; set; }

        /// <summary>
        /// Recognition result return form: 0 means the recognition result text (including segmented time stamps), 1 is the detailed recognition result at the word level granularity, without punctuation, and includes the speech rate value (a list of word time stamps, generally used to generate subtitle scenes), 2 Detailed recognition results at word-level granularity (including punctuation and speech rate values)..
        /// </summary>
        [Input("resTextFormat")]
        public Input<string>? ResTextFormat { get; set; }

        /// <summary>
        /// Whether to enable speaker separation: 0 means not enabled, 1 means enabled (only supports 8k_zh, 16k_zh, 16k_zh_video, monophonic audio), the default value is 0, Note: 8K telephony scenarios suggest using dual-channel to distinguish between the two parties, set ChannelNum=2 is enough, no need to enable speaker separation.
        /// </summary>
        [Input("speakerDiarization")]
        public Input<string>? SpeakerDiarization { get; set; }

        /// <summary>
        /// The number of speakers to be separated (need to be used in conjunction with enabling speaker separation), value range: 0-10, 0 means automatic separation (currently only supports &lt;= 6 people), 1-10 represents the number of specified speakers to be separated. The default value is 0.
        /// </summary>
        [Input("speakerNumber")]
        public Input<string>? SpeakerNumber { get; set; }

        public MediaSpeechRecognitionTemplateSpeechRecognitionArgs()
        {
        }
        public static new MediaSpeechRecognitionTemplateSpeechRecognitionArgs Empty => new MediaSpeechRecognitionTemplateSpeechRecognitionArgs();
    }
}
